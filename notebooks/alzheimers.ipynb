{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1223040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in ./.venv/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->kagglehub) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a362ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srinivasankarunakaran/Documents/Projects/ML-Alzheimers/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/srinivasankarunakaran/.cache/kagglehub/datasets/yiweilu2033/well-documented-alzheimers-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yiweilu2033/well-documented-alzheimers-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4b911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1614f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Age</th>\n",
       "      <th>Educ</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "      <th>Delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAS1_0001_MR1</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OAS1_0002_MR1</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "      <td>55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAS1_0003_MR1</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.207</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAS1_0004_MR1</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1588</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1.105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAS1_0005_MR1</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1737</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  \\\n",
       "0  OAS1_0001_MR1   F    R   74   2.0  3.0  29.0  0.0  1344  0.743  1.306   \n",
       "1  OAS1_0002_MR1   F    R   55   4.0  1.0  29.0  0.0  1147  0.810  1.531   \n",
       "2  OAS1_0003_MR1   F    R   73   4.0  3.0  27.0  0.5  1454  0.708  1.207   \n",
       "3  OAS1_0004_MR1   M    R   28   NaN  NaN   NaN  NaN  1588  0.803  1.105   \n",
       "4  OAS1_0005_MR1   M    R   18   NaN  NaN   NaN  NaN  1737  0.848  1.010   \n",
       "\n",
       "   Delay  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = '/Users/srinivasankarunakaran/.cache/kagglehub/datasets/yiweilu2033/well-documented-alzheimers-dataset/versions/2/oasis_cross-sectional-5708aa0a98d82080 (1).xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d34b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/qh_7c3n13xj3wn834lv9_qrw0000gp/T/ipykernel_7176/1212062878.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['SES'].fillna(df['SES'].median(), inplace=True)\n",
      "/var/folders/81/qh_7c3n13xj3wn834lv9_qrw0000gp/T/ipykernel_7176/1212062878.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['MMSE'].fillna(df['MMSE'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "# Fill missing values\n",
    "df['SES'].fillna(df['SES'].median(), inplace=True)\n",
    "df['MMSE'].fillna(df['MMSE'].mean(), inplace=True)\n",
    "\n",
    "# Drop rows with missing 'CDR'\n",
    "df.dropna(subset=['CDR'], inplace=True)\n",
    "\n",
    "# Encode 'M/F' column\n",
    "df['M/F'] = df['M/F'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# Select features and target\n",
    "features = ['M/F', 'Age', 'Educ', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']\n",
    "target = 'CDR'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Binarize the target variable (0 for non-demented, 1 for demented)\n",
    "y = y.apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce62a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8297872340425532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86        27\n",
      "           1       0.88      0.70      0.78        20\n",
      "\n",
      "    accuracy                           0.83        47\n",
      "   macro avg       0.84      0.81      0.82        47\n",
      "weighted avg       0.84      0.83      0.83        47\n",
      "\n",
      "CSV model exported as alzheimers_csv_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "model_csv = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_csv.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model_csv.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Export the model\n",
    "joblib.dump(model_csv, 'alzheimers_csv_model.joblib')\n",
    "print(\"CSV model exported as alzheimers_csv_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "base_dir = '/Users/srinivasankarunakaran/.cache/kagglehub/datasets/yiweilu2033/well-documented-alzheimers-dataset/versions/2'\n",
    "classes = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n",
    "image_files = []\n",
    "labels = []\n",
    "\n",
    "# Correct path for image classes\n",
    "class_paths = {\n",
    "    'NonDemented': os.path.join(base_dir, 'NonDemented (2)', 'NonDemented'),\n",
    "    'VeryMildDemented': os.path.join(base_dir, 'VeryMildDemented', 'VeryMildDemented'),\n",
    "    'MildDemented': os.path.join(base_dir, 'MildDemented', 'MildDemented'),\n",
    "    'ModerateDemented': os.path.join(base_dir, 'ModerateDemented', 'ModerateDemented')\n",
    "}\n",
    "\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    cls_path = class_paths[cls]\n",
    "    if os.path.isdir(cls_path):\n",
    "        cls_files = [os.path.join(cls_path, f) for f in os.listdir(cls_path) if f.endswith('.png')]\n",
    "        # Limit to 1000 images per class\n",
    "        cls_files = cls_files[:1000]\n",
    "        image_files.extend(cls_files)\n",
    "        labels.extend([cls] * len(cls_files))  # Use class names instead of numeric labels\n",
    "\n",
    "# Stratified split\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    image_files, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Create dataframes for the generators\n",
    "train_df = pd.DataFrame({'filename': train_files, 'class': train_labels})\n",
    "val_df = pd.DataFrame({'filename': val_files, 'class': val_labels})\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b33a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Build the model\n",
    "model_image = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')  # 4 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_image.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_image.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Export the model\n",
    "model_image.save('alzheimers_image_model.h5')\n",
    "print(\"Image model exported as alzheimers_image_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas openpyxl scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages for visualization and anomaly detection\n",
    "%pip install matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load data again for visualization\n",
    "file_path = '/Users/srinivasankarunakaran/.cache/kagglehub/datasets/yiweilu2033/well-documented-alzheimers-dataset/versions/2/oasis_cross-sectional-5708aa0a98d82080 (1).xlsx'\n",
    "df_viz = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Dataset Shape:\", df_viz.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df_viz.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_viz.head())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df_viz.isnull().sum())\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df_viz['CDR'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21bc79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Distribution of Target Variable (CDR)\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Subplot 1: CDR Distribution\n",
    "plt.subplot(3, 3, 1)\n",
    "cdr_counts = df_viz['CDR'].value_counts()\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "plt.pie(cdr_counts.values, labels=cdr_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "plt.title('CDR Distribution (Dementia Severity)')\n",
    "\n",
    "# Subplot 2: Age Distribution by CDR\n",
    "plt.subplot(3, 3, 2)\n",
    "for cdr in sorted(df_viz['CDR'].unique()):\n",
    "    age_data = df_viz[df_viz['CDR'] == cdr]['Age']\n",
    "    plt.hist(age_data, alpha=0.7, label=f'CDR {cdr}', bins=15)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Age Distribution by CDR')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 3: Gender Distribution by CDR\n",
    "plt.subplot(3, 3, 3)\n",
    "gender_cdr = pd.crosstab(df_viz['M/F'], df_viz['CDR'])\n",
    "gender_cdr.plot(kind='bar', ax=plt.gca())\n",
    "plt.title('Gender Distribution by CDR')\n",
    "plt.xlabel('Gender (F/M)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Subplot 4: MMSE Score Distribution\n",
    "plt.subplot(3, 3, 4)\n",
    "df_viz['MMSE'].hist(bins=20, alpha=0.7, color='skyblue')\n",
    "plt.xlabel('MMSE Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('MMSE Score Distribution')\n",
    "\n",
    "# Subplot 5: Education Level vs CDR\n",
    "plt.subplot(3, 3, 5)\n",
    "sns.boxplot(data=df_viz, x='CDR', y='Educ')\n",
    "plt.title('Education Level by CDR')\n",
    "plt.xlabel('CDR')\n",
    "plt.ylabel('Education Years')\n",
    "\n",
    "# Subplot 6: Brain Volume (eTIV) Distribution\n",
    "plt.subplot(3, 3, 6)\n",
    "sns.violinplot(data=df_viz, x='CDR', y='eTIV')\n",
    "plt.title('Estimated Total Intracranial Volume by CDR')\n",
    "plt.xlabel('CDR')\n",
    "plt.ylabel('eTIV')\n",
    "\n",
    "# Subplot 7: Normalized Whole Brain Volume\n",
    "plt.subplot(3, 3, 7)\n",
    "sns.boxplot(data=df_viz, x='CDR', y='nWBV')\n",
    "plt.title('Normalized Whole Brain Volume by CDR')\n",
    "plt.xlabel('CDR')\n",
    "plt.ylabel('nWBV')\n",
    "\n",
    "# Subplot 8: SES Distribution\n",
    "plt.subplot(3, 3, 8)\n",
    "df_viz['SES'].hist(bins=10, alpha=0.7, color='lightcoral')\n",
    "plt.xlabel('Socioeconomic Status')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SES Distribution')\n",
    "\n",
    "# Subplot 9: Atlas Scaling Factor\n",
    "plt.subplot(3, 3, 9)\n",
    "sns.scatterplot(data=df_viz, x='Age', y='ASF', hue='CDR')\n",
    "plt.title('Atlas Scaling Factor vs Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('ASF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ead30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Correlation Matrix and Feature Relationships\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.subplot(2, 3, 1)\n",
    "# Select only numeric columns for correlation\n",
    "numeric_cols = df_viz.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df_viz[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Age vs MMSE relationship\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.scatterplot(data=df_viz, x='Age', y='MMSE', hue='CDR', alpha=0.7)\n",
    "plt.title('Age vs MMSE Score by CDR')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('MMSE Score')\n",
    "\n",
    "# Brain volume relationships\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.scatterplot(data=df_viz, x='eTIV', y='nWBV', hue='CDR', alpha=0.7)\n",
    "plt.title('Brain Volume Relationship')\n",
    "plt.xlabel('Estimated Total Intracranial Volume')\n",
    "plt.ylabel('Normalized Whole Brain Volume')\n",
    "\n",
    "# Education vs SES\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.scatterplot(data=df_viz, x='Educ', y='SES', hue='CDR', alpha=0.7)\n",
    "plt.title('Education vs Socioeconomic Status')\n",
    "plt.xlabel('Education (Years)')\n",
    "plt.ylabel('Socioeconomic Status')\n",
    "\n",
    "# MMSE distribution by CDR\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.violinplot(data=df_viz, x='CDR', y='MMSE')\n",
    "plt.title('MMSE Score Distribution by CDR')\n",
    "plt.xlabel('CDR (Dementia Rating)')\n",
    "plt.ylabel('MMSE Score')\n",
    "\n",
    "# Age distribution\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.histplot(data=df_viz, x='Age', hue='CDR', multiple='stack', alpha=0.7)\n",
    "plt.title('Age Distribution by CDR')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Anomaly and Outlier Detection\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Prepare data for anomaly detection\n",
    "df_clean = df_viz.copy()\n",
    "df_clean['M/F'] = df_clean['M/F'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# Drop rows with missing CDR values (our target variable)\n",
    "df_clean = df_clean.dropna(subset=['CDR'])\n",
    "\n",
    "# Fill missing values with median for numeric columns\n",
    "numeric_columns = ['Educ', 'SES', 'MMSE']\n",
    "for col in numeric_columns:\n",
    "    df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "# Select features for anomaly detection\n",
    "features_for_anomaly = ['M/F', 'Age', 'Educ', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']\n",
    "X_anomaly = df_clean[features_for_anomaly]\n",
    "\n",
    "print(f\"Data shape after cleaning: {X_anomaly.shape}\")\n",
    "print(f\"Features used: {features_for_anomaly}\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_anomaly)\n",
    "\n",
    "# 1. Isolation Forest for Anomaly Detection\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "anomaly_labels = iso_forest.fit_predict(X_scaled)\n",
    "df_clean['Anomaly'] = anomaly_labels\n",
    "\n",
    "# Count anomalies\n",
    "normal_count = np.sum(anomaly_labels == 1)\n",
    "anomaly_count = np.sum(anomaly_labels == -1)\n",
    "\n",
    "print(f\"Normal samples: {normal_count}\")\n",
    "print(f\"Anomalies detected: {anomaly_count}\")\n",
    "print(f\"Anomaly percentage: {(anomaly_count / len(anomaly_labels)) * 100:.2f}%\")\n",
    "\n",
    "# Subplot 1: Anomaly Distribution\n",
    "plt.subplot(3, 4, 1)\n",
    "anomaly_counts = pd.Series(anomaly_labels).value_counts()\n",
    "labels = ['Normal', 'Anomaly']\n",
    "colors = ['lightgreen', 'red']\n",
    "plt.pie(anomaly_counts.values, labels=labels, autopct='%1.1f%%', colors=colors)\n",
    "plt.title('Anomaly Detection Results')\n",
    "\n",
    "# Subplot 2: Age vs MMSE with anomalies highlighted\n",
    "plt.subplot(3, 4, 2)\n",
    "normal_data = df_clean[df_clean['Anomaly'] == 1]\n",
    "anomaly_data = df_clean[df_clean['Anomaly'] == -1]\n",
    "plt.scatter(normal_data['Age'], normal_data['MMSE'], c='blue', alpha=0.6, label='Normal', s=30)\n",
    "plt.scatter(anomaly_data['Age'], anomaly_data['MMSE'], c='red', alpha=0.8, label='Anomaly', s=50)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('MMSE Score')\n",
    "plt.title('Age vs MMSE (Anomalies Highlighted)')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 3: Boxplot for Age outliers\n",
    "plt.subplot(3, 4, 3)\n",
    "sns.boxplot(data=df_clean, y='Age')\n",
    "plt.title('Age Distribution - Outlier Detection')\n",
    "plt.ylabel('Age')\n",
    "\n",
    "# Subplot 4: Boxplot for MMSE outliers\n",
    "plt.subplot(3, 4, 4)\n",
    "sns.boxplot(data=df_clean, y='MMSE')\n",
    "plt.title('MMSE Score - Outlier Detection')\n",
    "plt.ylabel('MMSE Score')\n",
    "\n",
    "# Subplot 5: Brain volume outliers\n",
    "plt.subplot(3, 4, 5)\n",
    "sns.boxplot(data=df_clean, y='eTIV')\n",
    "plt.title('eTIV - Outlier Detection')\n",
    "plt.ylabel('eTIV')\n",
    "\n",
    "# Subplot 6: Normalized brain volume outliers\n",
    "plt.subplot(3, 4, 6)\n",
    "sns.boxplot(data=df_clean, y='nWBV')\n",
    "plt.title('nWBV - Outlier Detection')\n",
    "plt.ylabel('nWBV')\n",
    "\n",
    "# Subplot 7: Education outliers\n",
    "plt.subplot(3, 4, 7)\n",
    "sns.boxplot(data=df_clean, y='Educ')\n",
    "plt.title('Education - Outlier Detection')\n",
    "plt.ylabel('Education Years')\n",
    "\n",
    "# Subplot 8: SES outliers\n",
    "plt.subplot(3, 4, 8)\n",
    "sns.boxplot(data=df_clean, y='SES')\n",
    "plt.title('SES - Outlier Detection')\n",
    "plt.ylabel('Socioeconomic Status')\n",
    "\n",
    "# Subplot 9: Brain volume relationship with anomalies\n",
    "plt.subplot(3, 4, 9)\n",
    "plt.scatter(normal_data['eTIV'], normal_data['nWBV'], c='blue', alpha=0.6, label='Normal', s=30)\n",
    "plt.scatter(anomaly_data['eTIV'], anomaly_data['nWBV'], c='red', alpha=0.8, label='Anomaly', s=50)\n",
    "plt.xlabel('eTIV')\n",
    "plt.ylabel('nWBV')\n",
    "plt.title('Brain Volume Relationship (Anomalies)')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 10: CDR distribution among anomalies\n",
    "plt.subplot(3, 4, 10)\n",
    "anomaly_cdr = anomaly_data['CDR'].value_counts()\n",
    "normal_cdr = normal_data['CDR'].value_counts()\n",
    "x_pos = np.arange(len(anomaly_cdr.index))\n",
    "width = 0.35\n",
    "plt.bar(x_pos - width/2, [normal_cdr.get(i, 0) for i in anomaly_cdr.index], \n",
    "        width, label='Normal', alpha=0.7)\n",
    "plt.bar(x_pos + width/2, anomaly_cdr.values, width, label='Anomaly', alpha=0.7)\n",
    "plt.xlabel('CDR')\n",
    "plt.ylabel('Count')\n",
    "plt.title('CDR Distribution: Normal vs Anomalies')\n",
    "plt.xticks(x_pos, anomaly_cdr.index)\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 11: Feature importance for anomaly detection\n",
    "plt.subplot(3, 4, 11)\n",
    "feature_means_normal = normal_data[features_for_anomaly].mean()\n",
    "feature_means_anomaly = anomaly_data[features_for_anomaly].mean()\n",
    "x_pos = np.arange(len(features_for_anomaly))\n",
    "width = 0.35\n",
    "plt.bar(x_pos - width/2, feature_means_normal, width, label='Normal', alpha=0.7)\n",
    "plt.bar(x_pos + width/2, feature_means_anomaly, width, label='Anomaly', alpha=0.7)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.title('Feature Means: Normal vs Anomalies')\n",
    "plt.xticks(x_pos, features_for_anomaly, rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 12: ASF outliers\n",
    "plt.subplot(3, 4, 12)\n",
    "sns.boxplot(data=df_clean, y='ASF')\n",
    "plt.title('ASF - Outlier Detection')\n",
    "plt.ylabel('Atlas Scaling Factor')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Test both models with sample data\n",
    "# No need for cv2, we'll use keras image preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TESTING BOTH MODELS WITH SAMPLE DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test CSV Model\n",
    "print(\"\\n1. TESTING CSV MODEL:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Load the CSV model\n",
    "csv_model = joblib.load('alzheimers_csv_model.joblib')\n",
    "\n",
    "# Get a random sample from the test data\n",
    "sample_idx = np.random.randint(0, len(X_test))\n",
    "sample_data = X_test.iloc[sample_idx:sample_idx+1]\n",
    "actual_label = y_test.iloc[sample_idx]\n",
    "\n",
    "print(f\"Sample data (row {sample_idx}):\")\n",
    "print(sample_data)\n",
    "print(f\"\\nActual label: {actual_label} ({'Non-Demented' if actual_label == 0 else 'Demented'})\")\n",
    "\n",
    "# Make prediction\n",
    "csv_prediction = csv_model.predict(sample_data)[0]\n",
    "csv_probability = csv_model.predict_proba(sample_data)[0]\n",
    "\n",
    "print(f\"CSV Model Prediction: {csv_prediction} ({'Non-Demented' if csv_prediction == 0 else 'Demented'})\")\n",
    "print(f\"Prediction Probabilities: Non-Demented={csv_probability[0]:.3f}, Demented={csv_probability[1]:.3f}\")\n",
    "\n",
    "# Test Image Model\n",
    "print(\"\\n\\n2. TESTING IMAGE MODEL:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Load the image model\n",
    "image_model = load_model('alzheimers_image_model.h5')\n",
    "\n",
    "# Get a random image from the dataset\n",
    "random_class = np.random.choice(classes)\n",
    "random_class_path = class_paths[random_class]\n",
    "\n",
    "print(f\"Testing with class: {random_class}\")\n",
    "print(f\"Class path: {random_class_path}\")\n",
    "\n",
    "if os.path.isdir(random_class_path):\n",
    "    # Get all image files\n",
    "    image_extensions = ['*.png', '*.jpg', '*.jpeg']\n",
    "    image_files_test = []\n",
    "    for ext in image_extensions:\n",
    "        image_files_test.extend(glob.glob(os.path.join(random_class_path, ext)))\n",
    "    \n",
    "    if image_files_test:\n",
    "        random_image_file = np.random.choice(image_files_test)\n",
    "        \n",
    "        print(f\"Testing image: {os.path.basename(random_image_file)}\")\n",
    "        print(f\"Actual class: {random_class}\")\n",
    "        print(f\"Image path: {random_image_file}\")\n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        img = image.load_img(random_image_file, target_size=(128, 128))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "        \n",
    "        # Make prediction\n",
    "        image_predictions = image_model.predict(img_array, verbose=0)\n",
    "        predicted_class_idx = np.argmax(image_predictions[0])\n",
    "        predicted_class = classes[predicted_class_idx]\n",
    "        confidence = image_predictions[0][predicted_class_idx]\n",
    "        \n",
    "        print(f\"\\nImage Model Prediction: {predicted_class}\")\n",
    "        print(f\"Confidence: {confidence:.3f}\")\n",
    "        print(f\"All class probabilities:\")\n",
    "        for i, class_name in enumerate(classes):\n",
    "            print(f\"  {class_name}: {image_predictions[0][i]:.3f}\")\n",
    "        \n",
    "        # Display the test image\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Test Image\\nActual: {random_class}\\nPredicted: {predicted_class}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Show prediction probabilities\n",
    "        plt.subplot(1, 2, 2)\n",
    "        bars = plt.bar(classes, image_predictions[0])\n",
    "        plt.title('Prediction Probabilities')\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Highlight the predicted class\n",
    "        bars[predicted_class_idx].set_color('red')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nPrediction Result: {'✓ CORRECT' if predicted_class == random_class else '✗ INCORRECT'}\")\n",
    "    else:\n",
    "        print(\"No image files found in the selected class directory\")\n",
    "        print(\"Available files:\", os.listdir(random_class_path)[:5] if os.path.isdir(random_class_path) else \"Directory not found\")\n",
    "else:\n",
    "    print(f\"Directory not found: {random_class_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL TESTING COMPLETED\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
